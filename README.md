# brainhack_lucca_2025

Project: 
Human brain is able to track hierarchical information embedded in naturalistic continuous speech. What about a phantom head with no brain but an artificial ear? 
The project aims to decode speech features information embedded in stories presented as audiobooks using activity recorded from an EEG phantom head equipped with a device converting sounds into electrical signals. The hierarchical speech features that we will try to decode include low-level acoustic features (e.g., envelope and spectrogram) and higher-level linguistic features (e.g., word frequency and lexical surprisal). We will assess how well this ‘brain-less’ EEG captures different information embedded in the speech signal by directly comparing it to real-brain EEG. 
What makes this project exciting is that we will try to test speech features decoding in a fully controlled, artificial system. To get started, one can begin by familiarizing themselves with EEG recording data and acoustic and linguistic features that can be extracted from continuous speech. 
Whether you are an expert or a complete beginner in decoding continuous, naturalistic information from EEG signals, it is a unique opportunity to learn and master cutting-edge neuroscience skills to work with ecological continuous stimuli. Plus, how many people can say they’ve worked with EEG activity from a phantom head?

Subjects info: 
1025 e 1026: soggetti umani
1115_Bi: phantom head con entrambe le orecchie artificiali
1115_sx: phantom head con orecchio sinistro 
1115_dx: phantom head con orecchio destro 
